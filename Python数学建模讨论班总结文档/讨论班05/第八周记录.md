# 线性回归和数据清洗

----

负责人：刘俊涵

---

## 1.一元线性回归模型

模型研究变量间的关系，变量间的关系有确定性关系（可以用函数来表示，一个x对应一个y）和相关关系（不能用函数来表示，一个x可能对应好几个y）。

一元线性模型可用来解释相关关系
$$
y=\beta_0+\beta_1x+\epsilon
$$
其中$\beta_0$和$\beta_1$是未知待定常数，$\epsilon$表示其他随机因素对y的影响，满足$N(0,\sigma^2)$分布。

### 1.2参数$\beta_0$和$\beta_1$的最小二乘估计

利用最小二乘法刻画接近程度

用最小二乘法刻画“接近程度”，使y的观察值与估计值偏差的平方和最小，即只需求函数
$$
Q=\sum_{i=1}^n (y_i-\beta_0-\beta_1 x_i)^2
$$
**好处**：绝对值不好求导，平方可微，在数学上性质好一点，所以一般用最小二乘法

Q是$\beta_0$和$\beta_1$的函数，可以用求偏导的方法求得

**自由度**：独立的变量个数

### 1.3相关性检验与判定系数（拟合优度）

采用样本方差的方法来测度

$SST=\sum_{i=1}^{n}(y_i-\overline y)^2=L_{yy}$，这是原始数据$y_i$的总变异平方和，其自由度为$df_T=n-1$；

$SSR=\sum_{i=1}^n(\hat y-\overline y)^2$，这是用拟合直线$\hat y_i=\hat \beta_0 +\hat \beta_1 x_i$可解释的变异平方和，其自由度为$df_R=1$

$SSE=\sum_i^n(y_i-\hat y_i)^2$,这是残差平方和，其自由度为$df_E=n-2$

注：这里$(\hat y_i - \overline y)$和$(y_i-\hat y_i)$正交，所以自由度可以直接通过相加计算，否则左右相加自由度不一定相等

（1）SSR越大，用回归方程来解释$y_i$变异的部分越大，回归方程对原数据解释得越好；

（2）SSE越小，观测值$y_i$绕回归直线越紧密，回归方程对原数据的拟合效果越好。

判定系数是指可解释的变异占总变异的百分比，用$R^2$表示，
$$
R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}
$$
$R^2$有以下几个简单性质

（1）$0\le R^2\le 1$

（2）$R^2=1$时，有SSR=SST，此时原数据的总变异可以完全由拟合值的变异来解释，残差为0

（3）$R^2=0$时，回归方程完全不能解释原数据的总变异，y的变异有与x无关的因素引起

### 1.4回归方程的显著性检验

实际应用中，需要检验$f(x)$是否为x的线性函数

利用检验统计量
$$
F=\frac{SSR}{SSE/(n-2)}~F(1,n-2)
$$
查表，决策规则如下：

（1）$F_{0.01}(1,n-2)<F$，线性关系显著

（2）$F_{0.05}(1,n-2)<F<F_{0.01}(1,n-2)$，线性关系显著

（3）$F<F_{0.05}(1,n-2)$，无线性关系

### 1.5一元线性回归举例

步骤一 根据数据做散点图

步骤二 求回归系数的点估计

>NumPy库提供了polyfit函数
>
>np.polyfit(x,y,deg=n)用于拟合n次多项式，n次多项式和线性关系式的求法是一样的
>
>最后返回一个list，从小到大分别是指数从大到小，比如当n=1时，p[0]表示x的系数，p[1]表示常数项系数
>
>np.polyval(p,x)可以用拟合好的系数来求拟合的值

```python
import matplotlib.pyplot as plt
import numpy as np
x=[2.5, 3.9, 2.9, 2.4, 2.9, 0.8, 9.1, 0.8, 0.7,7.9, 1.8, 1.9, 0.8, 6.5, 1.6, 5.8, 1.3, 1.2, 2.7]
y=[211, 167, 131, 191, 220, 297, 71, 211, 300, 107,
   167, 266, 277, 86, 207, 115, 285, 199, 172]
plt.plot(x,y,'+k', label="原始数据点")
p=np.polyfit(x,y,deg=1)  #拟合一次多项式 deg=2 可以拟合二次多项式
#返回次数为 n 的多项式 p(x) 的系数，该阶数是 y 中数据的最佳拟合（在最小二乘方式中）
print("拟合的多项式为:{}*x+{}".format(p[0],p[1]))
plt.rc('font',size=16); plt.rc('font',family='SimHei')#SimHei 黑体
plt.plot(x, np.polyval(p,x), label="拟合的直线")
print("预测值为：", np.polyval(p, 8)); plt.legend()
plt.savefig("figure4_25.png", dpi=500); plt.show()#dpi 分辨率
```

## 2.数据清洗

处理数据的时候，得到的表格不一定是完整的数据，即使是完整的数据，也有可能有异常的地方。

本节介绍**如何识别和处理重复观测、缺失值和异常值**。

### 2.1重复观测

> **Pandas**提供了检测和删除重复的记录的功能
>
> **Pandas**中使用**duplicated**方法，该方法返回的是数据行每一行的检验结果，即每一行返回一个**bool**值。使用**drop_duplicates**方法移除重复值。

`Pex4_26.py`

```python
import pandas as pd
a=pd.read_excel("Pdata4_26_1.xlsx")
print("是否存在重复观测：",any(a.duplicated()))  #输出：True
# a.drop_duplicates(self,subset=['id',...],keep='first')
# subset是列名的list，可以按照这些列来判断是否重复，keep=‘first’表示保留的是重复记录中的第一个
a.drop_duplicates(inplace=True)  #inplace=True时，直接删除a中的重复数据
f=pd.ExcelWriter('Pdata4_26_2.xlsx')  #创建文件对象
a.to_excel(f)  #把a写入新Excel文件中
f.save()       #保存文件，数据才真正写入Excel文件
```

### 2.2缺失值

**【nan】not a number**

> **Pandas**使用浮点值**NaN**表示浮点或非浮点数组中的缺失数据，Python内置的None值也会被当作缺失值处理。**Pandas**中使用方法**isnull**检测是否为缺失值，检测对象的每个元素返回一个**bool值**。

**检测缺失值**

```python
from numpy import NaN
from pandas import Series
data=Series([10.0, None, 20, NaN, 30])
print(data.isnull())  #输出每个元素的检测结果
print("是否存在缺失值：", any(data.isnull()))  #输出：True
```

输出

```bash
0    False
1     True
2    False
3     True
4    False
dtype: bool
是否存在缺失值： True
```

输出True，说明这个位置是缺失，any()函数只要有True，就返回True。

**去掉缺失值**

> Pandas中提供dropna和drop两个函数用于删除缺失值

```bash
#程序文件Pex4_28.py
from pandas import read_excel
a=read_excel("Pdata2_33.xlsx",usecols=range(1,4))
b1=a.dropna()  #删除所有的缺失值  dropna(axis=0,how='any',thresh=None)
b2=a.dropna(axis=1, thresh=9)  #删除有效数据个数小于9的列
b3=a.drop('用户B', axis=1)      #删除用户B的数据
b4=a.drop(1, axis=0)           #删除'1'(int)行数据
```

**填补缺失值**

> Pandas中提供fillna函数来填补缺失值，value可以是一个字典

```python
#程序文件Pex4_29.py
from pandas import read_excel
from numpy import NaN
a=read_excel("Pdata4_29.xlsx")
#a['age',0]=NaN#也可以a.age[0]=NaN,但是会警告
a['age',0]=NaN
b1=a.fillna(0)  #用0填补所有的缺失值
b2=a.fillna(method='ffill')  #用前一行的值填补缺失值，第一行缺失值不处理
b3=a.fillna(method='bfill')  #用后一行的值填补，最后一行缺失值不处理
b4=a.fillna(value={'gender':a.gender.mode()[0],   #性别使用众数替换
                'age':a.age.mean(),          #年龄使用均值替换
                'income':a.income.median()}) #收入使用中位数替换
```

### 2.3异常值处理

**异常值检测**

异常值指一些不符合常理的值和一些极端的值

异常值检测有两种常用的方法：一种是标准差法，如3$\sigma$方法（极端异常值），2$\sigma$方法（异常值）；另一种是箱线图判别法。

若服从正态分布，还是用$\sigma$方法比较好，箱线图法用于比较对称的分布。

```python
a.counts.quantile(0.25) # 计算下四分位数
a.counts.quantile(0.75) # 计算上四分位数
```

**替换异常值**

超出上界的值用上界替换，小于下界的值用下界替换

```python
print("异常值替换前的数据统计特征",a.counts.describe())
UB=Q3+1.5*IQR
st=a.counts[a.counts<UB].max()  #找出低于判别上限的最大值
print("判别异常值的上限临界值为:",UB)
print("用以替换异常值的数据为：",st)
a.loc[a.counts>UB, 'counts']=st  #替换超过判别上限异常值
print("异常值替换后的数据统计特征",a.counts.describe())
```

### 3总结

本次讨论课主要讲授了一元线性方程和数据清洗，一元线性方程可以利用numpy来拟合和求值，正常的数学工具包几乎都有这个功能，数据清洗主要用的是pandas包，针对重复、缺失、异常值三类情况的处理。