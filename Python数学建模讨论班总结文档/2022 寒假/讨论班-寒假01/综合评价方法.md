# 综合评价方法

整理人：宋奕辰

总结人：王云申、谢浩强、李明阳、张正诚

------

## 1. 综合评价方法的基本理论与数据预处理

### 1.1  基本理论

- **定义：**综合评价问题，是指根据一个系统同时受到多种因素影响的特点，在综合考虑多个有关因素以后，依据多个相关指标对系统进行总评价的方法。

- **常用方法：**TOPSIS法、层次分析法、模糊综合评价法、灰色系统法、熵值法、线性加权法等。
- **基本要素：**评价对象、评价指标（多用评价指标向量的形式进行建模）、权重系数（权重和为1，且权重的大小代表评价指标的重要程度）、综合评价模型、评价者。
- **基本步骤：**评价指标体系的建立，评价指标的预处理，评价指标权重的确定，评价模型的选择。

在建立评价指标时，有两点需要注意：

①**指标具有多样性，**例如定性和定量指标之间不同，正向和负向的指标不同，在综合评价模型建立的过程中需要对指标进行处理，方便综合评价的计算；

②在综合评价的过程中，并非所有的指标都是有效的，所以需要在实际评价中对评价指标进行**筛选，**筛选方法有：**专家调研法**（根据专家意见进行筛选）、**最小均方差法**（根据指标的差异程度进行筛选）、**极大极小离差法**（本质上也是根据指标的差异程度进行筛选）



### 1.2  数据预处理

数据预处理主要包括三项内容：一致化处理、无量纲化处理和定性指标的定量化，下面分别介绍。

**一、指标的一致化处理：**

- **基本内容：**将不同类型的指标进行统一，例如将非极大型指标转化为极大型指标。
- **具体方法：**

**1.极小型指标**转化为极大型指标

极小型指标$x_j$，转化为极大型指标时，可以采用取倒数：
$$
{x_j}^{'}={1 \over x_j}
$$
或者平移变换的方法：
$$
{x_j}^{'}=M_j-x_j
$$
其中$M_j=max\{a_{ij}\}\ ,1\leqslant i\leqslant n$。

**2.居中型指标**转化为极大型指标

居中型指标$x_j$，令$M_j=\max_{1\leqslant i\leqslant n}\{a_{ij}\}$，$m_j=\min_{1\leqslant i\leqslant n}\{a_{ij}\}$，取
$$
x_j^{'}=\left\{
\begin{aligned}
&{{2(x_j-m_j)}\over{M_j-m_j}},m_j\leqslant x_j\leqslant {{M_j+m_j}\over2} \\
&{{2(M_j-x_j)}\over{M_j-m_j}},{{M_j+m_j}\over2}< x_j\leqslant M_j
\end{aligned}
\right.
$$
**3.区间型指标**转化为极大型指标

区间型指标$x_j$，$x_j$是取值介于区间$[b_j^{(1)},b_j^{(2)}]$内时为最好，指标离该区间越远就越差。令$M_j=\max_{1\leqslant i\leqslant n}\{a_{ij}\}$，$m_j=\min_{1\leqslant i\leqslant n}\{a_{ij}\}$，$c_j=max\{b_j^{(1)}-m_j,M_j-{b_j^{(2)}}\}$,取
$$
x_j^{'}=\left\{
\begin{aligned}
&1-{{b_j^{(1)}}-x_j \over c_j},x_j< b_j^{(1)} \\
&1,b_j^{(1)}\leqslant x_j\leqslant b_j^{(2)}\\
&1-{x_j-{b_j^{(2)}} \over c_j},x_j> b_j^{(2)}
\end{aligned}
\right.
$$
**二、指标的无量纲化处理**

- **基本内容：**将指标实际值转化为指标评价值
- **具体方法：**首先将指标变换为极大型指标$a_{ij}$

**1.标准样本变换法**（相对平均值的位移程度）
$$
a_{ij}^{*}={{a_{ij}-\mu_j}\over s_j}
$$
对于评价指标值$a_{ij}>0$的评价方法，该处理方法不适用。

**2.比例变换法**（相对极大值的比例大小）
$$
a_{ij}^{*}={a_{ij}\over \max_{1\leqslant i\leqslant n} a_{ij}}
$$
**3.向量归一化法**（在$n$维空间中的向量归一化）
$$
a_{ij}^{*}={a_{ij} \over \sqrt{\sum_1^na_{ij}^2}}
$$
**4.极差变换法**（利用数据的极差进行变换）
$$
a_{ij}^*={a_{ij}-\min_{1\leqslant i \leqslant n} a_{ij}\over{\max_{1\leqslant i\leqslant n}a_{ij}-\min_{1\leqslant i \leqslant n}a_{ij}}}
$$
变换前后的各指标值不成比例。

**5.功效系数法**（划定不允许值和满意值）
$$
a_{ij}^*=c+{a_{ij}-\min_{1\leqslant i\leqslant n}a_{ij}\over {\max_{1\leqslant i\leqslant n}a_{ij}-\min_{1\leqslant i \leqslant n}a_{ij}}}\times d
$$
一般可以取$c=60$，$d=40$。

**三、定性指标的定量化**

通过适当的方式，将定性的描述转化为定量的评价值。例如：

|  等级  | 很低 |  低  | 一般 |  高  | 很高 |
| :----: | :--: | :--: | :--: | :--: | :--: |
| 量化值 |  0   | 0.3  | 0.5  | 0.7  |  1   |



**例1：**

战斗机的性能指标主要包括最大速度、飞行半径、最大负载、隐身性能、垂直起降性能、可靠性、灵敏度等指标和相关费用。综合各方面因素与条件，忽略了隐身性能和垂直起降性能，只考虑余下的6项指标，请就 A1,A2,A3,A4四种类型战斗机的性能进行评价分析，其6 项指标值如下表所示：

|      | 最大速度（马赫） | 飞行范围(km) | 最大负载（磅） | 费用（美元） | 可靠性 | 灵敏度 |
| :--: | ---------------- | ------------ | -------------- | ------------ | ------ | ------ |
|  A1  | 2.0              | 1500         | 20000          | 5500000      | 一般   | 很高   |
|  A2  | 2.5              | 2700         | 18000          | 6500000      | 低     | 一般   |
|  A3  | 1.8              | 2000         | 21000          | 4500000      | 高     | 高     |
|  A4  | 2.2              | 1800         | 20000          | 5000000      | 一般   | 一般   |

假设将 6 项指标依次记为$x_1,x_2,...,x_6$，首先将$x_5$和$x_6$ 两项定性指标进行量化处理，量化后的数据如下表所示。

|      | 最大速度（马赫） | 飞行范围(km) | 最大负载（磅） | 费用（美元） | 可靠性 | 灵敏度 |
| :--: | ---------------- | ------------ | -------------- | ------------ | ------ | ------ |
|  A1  | 2.0              | 1500         | 20000          | 5500000      | 0.5    | 1      |
|  A2  | 2.5              | 2700         | 18000          | 6500000      | 0.3    | 0.5    |
|  A3  | 1.8              | 2000         | 21000          | 4500000      | 0.7    | 0.7    |
|  A4  | 2.2              | 1800         | 20000          | 5000000      | 0.5    | 0.5    |

数值型指标中$x_1,x_2,x_3$为极大型指标，费用$x_4$为极小型指标。下面给出几种处理方式的结果。采用向量归一化法对各指标进行标准化处理，可得评价矩阵$R_1$为:
$$
R_1=
\begin{bmatrix}

0.4671&0.3662&0.5056&0.4931&0.4811&0.7089\\
0.5839&0.6591&0.4550&0.4010&0.2887&0.3544\\
0.4204&0.4882&0.5308&0.5853&0.6736&0.4962\\
0.5139&0.4394&0.5056&0.5392&0.4811&0.3544

\end{bmatrix}
$$

采用比例变换法对各数值型指标进行标准化处理，可得评价矩阵$R_2$为:

$$
R_2=
\begin{bmatrix}

0.8&0.5556&0.9524&0.8182&0.7143&1\\
1&1&0.8571&0.6923&0.4286&0.5\\
0.72&0.7407&1&1&1&0.7\\
0.88&0.6667&0.9524&0.9&0.7143&0.5

\end{bmatrix}
$$

采用极差变换法对各数值型指标进行标准化处理，可得评价矩阵$R_3$为:

$$
R_3=
\begin{bmatrix}

0.2857&0&0.6667&0.5&0.5&1\\
1&1&0&0&0&0\\
0&0.4167&1&1&1&0.4\\
0.5714&0.25&0.75&0.75&0.5&0

\end{bmatrix}
$$

Python代码：

```python
import numpy as np
import pandas as pd
a=np.loadtxt("Pdata9_1_1.txt",)
R1=a.copy(); R2=a.copy(); R3=a.copy()  #初始化
#注意R1=a,它们的内存地址一样，R1改变时，a也改变
for j in [0,1,2,4,5]:
    R1[:,j]=R1[:,j]/np.linalg.norm(R1[:,j]) #向量归一化
    R2[:,j]=R1[:,j]/max(R1[:,j])     #比例变换
    R3[:,j]=(R3[:,j]-min(R3[:,j]))/(max(R3[:,j])-min(R3[:,j]));
R1[:,3]=1-R1[:,3]/np.linalg.norm(R1[:,3])
R2[:,3]=min(R2[:,3])/R2[:,3]
R3[:,3]=(max(R3[:,3])-R3[:,3])/(max(R3[:,3])-min(R3[:,3]))
np.savetxt("Pdata9_1_2.txt", R1); #把数据写入文本文件，供下面使用
np.savetxt("Pdata9_1_3.txt", R2); np.savetxt("Pdata9_1_4.txt", R3)
DR1=pd.DataFrame(R1)  #生成DataFrame类型数据
DR2=pd.DataFrame(R2); DR3=pd.DataFrame(R3)
f=pd.ExcelWriter('Pdata9_1_5.xlsx')  #创建文件对象
DR1.to_excel(f,"sheet1")  #把DR1写入Excel文件1号表单中,方便做表
DR2.to_excel(f,"sheet2"); DR3.to_excel(f, "Sheet3"); f.save()
```



## 2. 常用的综合评价数学模型

### 2.1  **线性加权综合评价模型**

1.建模方式：

​		权重系数向量$w=[w_1，w_2，...，w_m]$对每一个评价对象i，它的加权综合评价值为$f_i$，满足$f_i=∑_{j=1}^mw_jb_{ij}$

2.特点：

​	$∑_{j=1}^mw_j=1$，因此各不同指标之间可以线性相互补偿（前提是此模型适用于指标相互独立的情况）

​	评价结果依赖于权重系数，对于权重系数大的指标，其对综合指标作用较大



### 2.2  TOPSIS 法

TOPSIS法是理想解的排序方法（Technique for Order Preference by Similarity to Ideal Solution）

1、将评价指标进行预处理，即进行一致化（全部化为极大型指标）和无量纲化，并构造评价矩阵

2、确定正理想解和负理想解（每个评价指标规范化后的最大和最小值）

3、计算各评价对象到正理想解和负理想解的距离

4、计算各评价对象对理想解的相对接近度

5、按照接近度由大到小排列各评价对象的优劣次序

```python
import numpy as np
import pandas as pd
R2=np.loadtxt("Pdata9_1_3.txt",)
CP=[];CM=[]
for i in range(6):
    CP.append(np.max(R2[:,i]))
    CM.append(np.min(R2[:,i]))
print('正理想解： ','\n',CP,'\n','负理想解： ','\n',CM)
SP=[];SM=[]
for i in range(4):
    tmp1=0
    tmp2=0
    for j in range(6):
        tmp1=tmp1+(R2[i,j]-CP[j])*(R2[i,j]-CP[j])
        tmp2=tmp2+(R2[i,j]-CM[j])*(R2[i,j]-CM[j])
    SP.append(np.sqrt(tmp1))
    SM.append(np.sqrt(tmp2))
print('到正理想解距离：','\n',SP,'\n','到负理想解距离： ','\n',SM)
F=[]
for i in range(4):
    F.append(SM[i]/(SP[i]+SM[i]))
print('对理想解的相对接近度： ', F)
```

我们继续对**例1**进行分析，本次使用TOPSIS法。

(1)确定正理想和负理想解分别为：
$$
C^+=[1,1,1,1,1,1],\ C^-=[0.72,0.5556,0.8571,0.6923,0.4286,0.5]
$$
(2)由公式
$$
s_i^+=\sqrt{\sum_{j=1}^6(b_{ij}-c_j^+)^2},s_i^-=\sqrt{\sum_{j=1}^6(b_{ij}-c_j^-)^2}
$$
得到：
$$
s^+=[0.5954,0.8316,0.4854,0.66851],s^-=[0.6025,0.5253,0.7183,0.4145]
$$
(3)由公式$f_i=\frac{s_i^-}{s_i^-+s_i^+}$,  得到：
$$
F=[f_1,f_2,f_3,f_4]=[0.5029,0.3871,0.5967,0.3769]
$$
于是各机型优劣排序为：$A_3>A_1>A_2>A_4$.

### 2.3  灰色关联度分析

**具体步骤：**

1.预处理（一致化+无量纲化）

2.确定比较数列和参考数列：

​	参考数列是对每一个指标中最好的指标值构成的数列，记为$c_j=max_{1≤i≤n}b_{ij}$

3.计算灰色关联系数

​	为了介绍方便，先设$m_{min}=min_{1≤s≤n}min_{1≤k≤m}|c_k-b_{sk}|,\ \ m_{max}=max_{1≤s≤n}max_{1≤k≤m}|c_k-b_{sk}|$为两级最小差和两级最大差

​	称$ζ_{ij}=(m_{min}+ρ\ m_{max})/(|c_j-b_{ij}|+ρ\ m_{max})$为比较数列对参考数列在第$j$个指标上的关联系数,其中ρ为分辨系数。

4.计算灰色关联度

​	灰色关联度$r_i=∑_{j=1}^mw_jζ_{ij}$，其中w为权重系数

5.评价分析：r越大说明评价结果越好



### 2.4  熵值法

#### 1. 原理

​		在信息论中信息熵是信息不确定度的一种度量，一般而言，**信息量越大，熵值越小，信息的效用值越大，信息量越小，熵值越大，信息的效用值越小**

#### 2. 计算过程

设一共有$n$个评价对象，$m$个评价指标

(1) 计算第$j$项指标下第$i$个评价对象的特征比重

​	  设第$i$个评价对象的第$j$个观测值的标准化数据$b_{ij}  \geq 0 (i = 1,2,\cdots,n;j=1,2,\cdots,m)$，则在第$j$项指标下第$i$个评价对象的特征比重为：
$$
p_{ij} = \frac{b_{ij}}{\sum_{i=1}^n b_{ij}} (i = 1,2,\cdots,n;j=1,2,\cdots,m)
$$
(2) 计算熵值

第$j$项指标的熵值为：
$$
e_j = -\frac{1}{\ln n}\sum_{i=1}^{n}p_{ij}\ln p_{ij} (j=1,2,\cdots,m)
$$
ps: $p_{\_j}$差异越大，$e_j$越小。

(3) 计算第$j$项指标的差异系数为：
$$
g_j = 1-e_j
$$
ps：差异越大，$g_j$越大

(4) 确定第$j$项指标的权重系数：
$$
w_j = \frac{g_j}{\sum_{k=1}^{m}g_k}
$$
(5) 计算第$i$个对象的综合评价值：
$$
f_i = \sum_{j=1}^m w_j p_{ij}
$$
评价值越大越好

#### 3. 样例计算

我们继续对**例1**进行分析，本次使用熵值法。

#### (1) 计算第$j$项指标下第$i$个评价对象的特征比重

```python
# (1) 计算第$j$项指标下第$i$个评价对象的特征比重
p = np.zeros_like(b)
for i in range(4):
    for j in range(6):
        p[i,j] = b[i,j]/b[:,j].sum()
print(p)
# out:
'''
p [[0.23529412 0.18751266 0.25316994 0.23990617 0.25       0.37037037]
 [0.29411765 0.33749578 0.227837   0.20299076 0.150007   0.18518519]
 [0.21176471 0.24998313 0.26582312 0.29321214 0.349993   0.25925926]
 [0.25882353 0.22500844 0.25316994 0.26389093 0.25       0.18518519]]
'''
```

#### (2) 计算熵值

```python
# (2) 计算熵值
def Sum(j):
    t = 0
    for i in range(4):
        t += p[i,j]*log(p[i,j])
        # print(t)
    return t
e = []
for j in range(6):
    e.append(-1.0/log(4)*Sum(j))
print("e",e)
'''
out:
e [0.9946889252565125, 0.9829523936337596, 0.998886735136502, 0.9936175370554163, 0.9703270029272758, 0.9683688186345032]
'''
```

#### (3)计算第$j$项指标的差异系数为：

```python
# (3)计算第$j$项指标的差异系数为：
g = 1-np.array(e)
print(g)
'''
out:
g [0.00531107 0.01704761 0.00111326 0.00638246 0.029673   0.03163118]
'''
```

#### (4) 确定第$j$项指标的权重系数：

```python
# (4) 确定第$j$项指标的权重系数：
w = np.zeros(g.size)
for j in range(6):
    w[j] = g[j]/g.sum()
print('w',w)
'''
out:
w [0.05826192 0.18701043 0.0122124  0.07001494 0.32550962 0.34699069]
'''
```

#### (5) 计算第$i$个对象的综合评价值：

```python
f=np.zeros(4)
for i in range(4):
    for j in range(6):
        f[i] += w[j]*p[i,j]
print('f',f)
'''
out:
f [0.27855681 0.21033217 0.28674948 0.22436154]
'''
```

于是各机型优劣排序为：$A_3>A_1>A_4>A_2$.

### 2.5  秩和比（RSR）法

秩和比法（RSR, Rank Sum Ratio）的基本原理是在一个n行m列的矩阵中，通过秩转换，获得无量纲统计量RSR；以RSR值对评价对象的优劣直接排序，从而对评价对象做出综合评价。
1、对数据矩阵逐列编秩（指标相同时，编平均秩）
2、计算秩和比（RSR）
3、根据RSR排序，RSR越大评价越好

```python
import numpy as np
from scipy.stats import rankdata
a=np.loadtxt("Pdata9_1_3.txt",)
R=[rankdata(a[:,i]) for i in range(6)]  #求每一列的秩
#https://vimsky.com/examples/usage/python-scipy.stats.rankdata.html
R=np.array(R).T   #构造秩矩阵
print("\n秩矩阵为：\n",R)
RSR=R.mean(axis=1); print('\n',"RSR=", RSR/4)
```

我们继续对**例1**进行分析，本次使用RSR法。

最终得到的结果为：
$$
RSR=[0.5833,0.5208,0.7917,0.6042]
$$
得到各机型优劣排序为：$A_3>A_4>A_1>A_2$.  



## 3.  层次分析法（AHP）

由于该法内容较多，单独放在本节阐述。

### 3.1  基本概念

层次分析法（ Analytic Hierarchy Process，简称 **AHP**）是对一些较为复杂、较为模糊的问题作出决策的简易方法，它特别适用于那些难于完全定量分析的问题。它是美国运筹学家 T. L. Saaty 教授于上世纪 70 年代初期提出的一种简便、灵活而又实用的多准则决策方法。  

### 3.2  层次分析法的基本原理与步骤  

运用层次分析法建模，大体上可按下面四个步骤进行：
（1）建立**递阶层次结构**模型；
（2）构造出各层次中的所有**判断矩阵**；
（3）层次**单排序**及**一致性检验**；
（4）层次**总排序**及**一致性检验**  。

#### 3.2.1 递阶层次结构的建立与特点  

应用 AHP 分析决策问题时，首先要把问题条理化、层次化，构造出一个有层次的结构模型。在这个模型下，复杂问题被分解为元素的组成部分。这些元素又按其属性及关系形成若干层次。上一层次的元素作为准则对下一层次有关元素起支配作用。
这些层次可以分为三类：
（1）**最高层(目标层)**：这一层次中只有一个元素，一般它是分析问题的预定目标或理想结果，因此也称为目标层。
（2）**中间层(准则层)**：这一层次中包含了为实现目标所涉及的中间环节，它可以由若干个层次组成，包括所需考虑的准则、子准则，因此也称为准则层。
（3）**最底层(方案层)**：这一层次包括了为实现目标可供选择的各种措施、决策方案等，因此也称为措施层或方案层。

​		递阶层次结构中的层次数与问题的复杂程度及需要分析的详尽程度有关，一般地层次数不受限制。每一层次中各元素所支配的元素一般不要超过 9 个。这是因为支配的元素过多会给两两比较判断带来困难。  

* 一个实例

  假期旅游有$ P1、 P2 、 P3 $，3 个旅游胜地供你选择，试确定一个最佳地点。
  		在此问题中，你会根据诸如景色、费用、居住、饮食和旅途条件等一些准则去反复比较 3 个侯选地点。可以建立如图的层次结构模型  ：

  ![image-20220123133431922](https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123133431922.png)

  

#### 3.2.2 构造判断矩阵  

​		层次结构反映了因素之间的关系，但准则层中的各准则在目标衡量中所占的比重并不一定相同，在决策者的心目中，它们各占有一定的比例。  

设现在要比较$ n $个因子$ X = \{x_1,\cdots, x_n\} $对某因素$ Z $的影响大小， 怎样比较才能提供可信的数据呢？***Saaty*** 等人建议可以采取对因子进行两两比较建立成对比较矩阵的办法。即每次取两个因子$ x_i $和$ x_j $，以$ a_{ij} $表示$ xi $和$ x_j $对$ Z $的影响大小之比，全部比较结果用矩阵$A = (a_{ij} )_{n×n} $表示，称$ A $为$ Z - X $之间的成对比较判断矩阵（简称判断矩阵）。容易看出，若$ x_i $与$ x_j $对$ Z $的影响之比为$ a_{ij} $，则$ x_j $与$ x_i $对$ Z $的影响之比应为$a_{ji} = \frac{1}{a_{ij}}$

* **定义**

  若矩阵$A = (a_{ij} )_{n×n} $满足
  (1) $a_{ij} > 0$  		(2)$a_{ji} = \frac{1}{a_{ij}}$  		(3) 易知 $a_{ii} = 1 (i=1,2,\cdots,n)$

  则称$A$为正互反矩阵

关于如何确定$a_{ij} $的值， ***Saaty*** 等建议引用数字 $1\sim9$ 及其倒数作为标度。下表列出了$1\sim9 $标度的含义：  

![image-20220123152938962](https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123152938962.png)

最后，应该指出，一般地作$\frac{n(n-1)}{2}$次两两判断是必要的。有人认为把所有元素都和某个元素比较，即只作$n-1$ 次比较就可以了。这种作法的弊病在于，任何一个判断的失误均可导致不合理的排序，而个别判断的失误对于难以定量的系统往往是难以避免的。进行$C_n^2$次比较可以提供更多的信息，通过各种不同角度的反复比较，从而导出一个合理的排序。

#### 3.2.3 层次单排序及一致性检验  

##### 3.2.3.1 层次单排序

​		判断矩阵$ A $对应于最大特征值$\lambda_{max}$ 的特征向量$W$，经归一化后即为同一层次相应因素对于上一层次某因素相对重要性的排序权值，这一过程称为**层次单排序**。

##### 3.2.3.2 一致性检验

* **定义**:

  满足下列关系式的正互反矩阵$A$称为**一致矩阵**：
  $$
  a_{ij}a_{jk} = a_{ik}
  $$

​		上述构造成对比较判断矩阵的办法虽能减少其它因素的干扰，较客观地反映出一对因子影响力的差别。但综合全部比较结果时，其中难免包含一定程度的非一致性。如果比较结果是前后完全一致的，则矩阵$ A $应为一致矩阵。**需要检验构造出来的（正互反）判断矩阵 A 是否严重地非一致，以便确定是否接受$ A $。**  

* 需应用矩阵论定理：

  * **定理一**：

    正互反矩阵$ A $的最大特征根$λ_max $必为正实数，其对应特征向量的所有分量均为正实数。$ A $的其余特征值的模均严格小于$λ_max$ 。  

  * **定理二：**

    若$ A $为一致矩阵，则  ：

    1. $A $必为正互反矩阵。  
    2. $A $的转置矩阵$ A^T $也是一致矩阵。  
    3. $A $的任意两行成比例，比例因子大于零，从而$ rank(A) = 1 $（同样，$ A $的
       任意两列也成比例）。  
    4. $A $的最大特征值$λ_max = n$， 其中$ n $为矩阵 $A $的阶。 $A$ 的其余特征根均为零。  
    5. 若 A 的最大特征值$λ_max $对应的特征向量为$W = (w_1,\cdots, w_n )^T $， 则$a_{ij} = \frac{w_i}{w_j}$  

  * **定理三：**(判断依据)

    $n $阶正互反矩阵 $A $为一致矩阵当且仅当其最大特征根 $λ_max= n$，且当正互反矩阵$ A $非一致时，必有$λ_max > n$

​		根据定理 3，我们可以由$λ_max $是否等于 $n $来检验判断矩阵$ A $是否为一致矩阵。由于特征根连续地依赖于$a_{ij}$ ，故 $λ_max $比$ n $大得越多，$ A $的非一致性程度也就越严重。

* **检验方法：**

  1. 计算一致性指标$CI$
     $$
     CI = \frac{\lambda_{max}-n}{n-1}
     $$

  2. 查找相应的平均随机一致性指标$ RI $。对 $n = 1,\cdots,9 $，***Saaty*** 给出了$ RI $的值，
     如表所示。  

     ![image-20220123170251909](https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123170251909.png)

  3. 计算一致性比例$CR  $
     $$
     CR = \frac{CI}{RI}
     $$
     当$CR < 0.10 $时，认为判断矩阵的一致性是可以接受的，否则应对判断矩阵作适当修正。  

#### 3.2.4 层次总排序及一致性检验  

​		上面我们得到的是一组元素对其上一层中某元素的权重向量。我们最终要得到各元素，特别是最低层中各方案对于目标的排序权重，从而进行方案选择。总排序权重要自上而下地将单准则下的权重进行合成:

![image-20220123170715668](https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123170715668.png)

​		对层次总排序也需作一致性检验，检验仍象层次总排序那样由高层到低层逐层进行。这是因为虽然各层次均已经过层次单排序的一致性检验，各成对比较判断矩阵都已具有较为满意的一致性。但当综合考察时，各层次的非一致性仍有可能积累起来，引起最终分析结果较严重的非一致性。  

​		设 $B $层中与$A_j $相关的因素的成对比较判断矩阵在单排序中经一致性检验，求得单排序一致性指标为$CI( j) ， (j = 1,\cdots,m )$，相应的平均随机一致性指标为$ RI( j)(CI( j)、 RI( j) 已在层次单排序时求得)$，则$ B $层总排序随机一致性比例为:
$$
CR = \frac{\sum_{j=1}^{m}CI(j)a_j}{\sum_{j=1}^{m}RI(j)a_j}
$$
​		当$CR < 0.10 $时，认为层次总排序结果具有较满意的一致性并接受该分析结果。  

### 3.3 书上的一个案例

#### 3.3.1 问题背景

​		春天来了，张勇、李雨、王刚、赵宇四位大学生相约去寻找那生机勃勃、盎然向上的春天，去呼吸那沁人心脾春天的气息。 “五一”长假终于到了，但他们却发生了争执。原来张勇想到风光绮丽的苏杭去看园林的春色，李雨却想到风景迷人的黄山去看巍峨挺拔的黄山松，王刚则想到风光秀丽的庐山去寻找庐山的真面目。三个人争得面红耳赤，只有赵宇坐在一旁手里拿着笔，不停地写着，最后站起来说： “别吵了， 我计算过了，去苏杭是明智的选择。 ”说着他拿起笔在纸上画一张分析图（如图 9.1 所示），并讲解起来。  

#### 3.3.2 层次结构建立

<img src="https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123171554149.png" alt="image-20220123171554149" style="zoom:67%;" />

#### 3.3.3 构造判断矩阵

##### 3.3.3.1 优先级确定

<img src="https://gitee.com/mr_asd/taolunban-img/raw/master/images/image-20220123171644327.png" alt="image-20220123171644327" style="zoom:67%;" />

##### 3.3.3.2 构造$A$

$$
A = \left[
\begin{matrix}
1 & \frac{1}{2}& 5& 5& 3 \\
2 & 1 &7&7&5 \\
\frac{1}{5}& \frac{1}{7}& 1&\frac{1}{2}&\frac{1}{3}& \\
\frac{1}{5}& \frac{1}{7}& 2& 1& \frac{1}{2}& \\
\frac{1}{3}& \frac{1}{5}& 3&2&1
\end{matrix}
\right]
$$

#### 3.3.4 层次排序

利用 Python 可以求出最大特征值$\lambda_max = 5.0976$，对应的特征向量经归一化得
$$
W = [0.2863, 0.4809, 0.0485, 0.0685, 0.1157]^T
$$
各层次排序：
$$
\begin{array}{l}
B_{1}(\text { 景色 })=\left[\begin{array}{ccc}
1 & 1 / 3 & 1 / 2 \\
3 & 1 & 1 / 2 \\
2 & 2 & 1
\end{array}\right], \quad P_{1}=\left[\begin{array}{l}
0.1677 \\
0.3487 \\
0.4836
\end{array}\right], \\
B_{2} \text { (费用) }=\left[\begin{array}{ccc}
1 & 3 & 2 \\
1 / 3 & 1 & 2 \\
1 / 2 & 1 / 2 & 1
\end{array}\right], \quad P_{2}=\left[\begin{array}{l}
0.5472 \\
0.2631 \\
0.1897
\end{array}\right], \\
B_{3} \text { (饮食) }=\left[\begin{array}{ccc}
1 & 4 & 3 \\
1 / 4 & 1 & 2 \\
1 / 3 & 1 / 2 & 1
\end{array}\right], \quad P_{3}=\left[\begin{array}{l}
0.6301 \\
0.2184 \\
0.1515
\end{array}\right], \\
B_{4}(\text { 居住 })=\left[\begin{array}{ccc}
1 & 3 & 2 \\
1 / 3 & 1 & 2 \\
1 / 2 & 1 / 2 & 1
\end{array}\right], \quad P_{4}=\left[\begin{array}{l}
0.5472 \\
0.2631 \\
0.1897
\end{array}\right], \\
B_{5}(\text { 旅途 })=\left[\begin{array}{ccc}
1 & 2 & 3 \\
1 / 2 & 1 & 1 / 2 \\
1 / 3 & 2 & 1
\end{array}\right], \quad P_{5}=\left[\begin{array}{l}
0.5472 \\
0.1897 \\
0.2631
\end{array}\right],
\end{array}
$$
​		最后，将由各准则对目标的权向量$W $和各方案对每一准则的权向量，计算各方案对目标的权向量，称为组合权向量。

​		若记
$$
P=\left[P_{1}, P_{2}, P_{3}, P_{4}, P_{5}\right]=\left[\begin{array}{lllll}
0.1677 & 0.5472 & 0.6301 & 0.5472 & 0.5472 \\
0.3487 & 0.2631 & 0.2184 & 0.2631 & 0.1897 \\
0.4836 & 0.1897 & 0.1515 & 0.1897 & 0.2631
\end{array}\right],
$$
则根据矩阵乘法, 可得组合权向量
$$
K=\left[\begin{array}{l}
k_{1} \\
k_{2} \\
k_{3}
\end{array}\right]=P W=\left[\begin{array}{l}
0.4426 \\
0.2769 \\
0.2805
\end{array}\right] \text {. }
$$

#### 3.3.5 一致性检验

​		在上述模型中矩阵 $A$ 的一致性比率 $\mathrm{CR}=0.0218<0.1$, 通过了一致性检验。

#### 3.3.6 结果

​		上述结果表明: 方案 1 (苏杭) 在旅游选择中占的权重为 $0.4426$, 接近 $0.5$, 远大于方案 2 (黄山权重为 $0.2769$ )、方案 3 (庐山权重为 $0.2805$ ), 因此他们应该去苏杭。

#### 3.3.7 code

```python
from scipy.sparse.linalg import eigs
from numpy import array, hstack

a = array([[1, 1 / 2, 5, 5, 3], [2, 1, 7, 7, 5], [1 / 5, 1 / 7, 1, 1 / 2, 1 / 3],
           [1 / 5, 1 / 7, 2, 1, 1 / 2], [1 / 3, 1 / 5, 3, 2, 1]])

for x in range(1, 5):
    print("test", eigs(a, x))

L, V = eigs(a, 4)
print("test", L, "\n", V)
L = L[0];
V = V[0]
CR = (L - 5) / 4 / 1.12  # 计算矩阵 A 的一致性比率

W = V / sum(V)
print("最大特征值为： ", L)
print("最大特征值对应的特征向量 W=", W)
print("CR=", CR)

B1 = array([[1, 1 / 3, 1 / 2], [3, 1, 1 / 2], [2, 2, 1]])
L1, P1 = eigs(B1, 1)
P1 = P1 / sum(P1)
print("P1=", P1)

B2 = array([[1, 3, 2], [1 / 3, 1, 2], [1 / 2, 1 / 2, 1]])
t2, P2 = eigs(B2, 1)
P2 = P2 / sum(P2)
print("P2=", P2)

B3 = array([[1, 4, 3], [1 / 4, 1, 2], [1 / 3, 1 / 2, 1]])
t3, P3 = eigs(B3, 1)
P3 = P3 / sum(P3)
print("P3=", P3)

B4 = array([[1, 3, 2], [1 / 3, 1, 2], [1 / 2, 1 / 2, 1]])
t4, P4 = eigs(B4, 1)
P4 = P4 / sum(P4)
print("P4=", P4)

B5 = array([[1, 2, 3], [1 / 2, 1, 1 / 2], [1 / 3, 2, 1]])
t5, P5 = eigs(B5, 1)
P5 = P5 / sum(P5)
print("P5=", P5)

# hstack()横向打包
# vstack()纵向打包

K = hstack([P1, P2, P3, P4, P5]) @ W  # 矩阵乘法 @
print("K=", K)

```

